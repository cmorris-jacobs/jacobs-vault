{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#skip\n",
    "# Put any special code here e.g. `! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jacobs VAULT\n",
    " \n",
    "> **jacobs-vault** is Jacobs' response to the Air Force VAULT quick-turn data analysis challenge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAULT contains scripts and notebooks that (a) ingest and characterize the provided AIS shipping tracks and satellite TLE data, (b) find \"hits\" - satellites are visible for a given ship position, and (c) highlight coverage gaps / flaws in the data.  Here is an example starmap showing satellites visible from one point on track, colored by quality of the satellite's TLE data. \n",
    "<table>\n",
    "    <tr style=\"background-color:#EEEEEE\">\n",
    "        <td ><img src=\"images/Jacobs_logo_rgb_black.svg\" width=\"200\"/></td>\n",
    "        <td><img alt=\"Satellites Visible\" src=\"images/polar_plot2.png\" width=\"300\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "(For demo purposes, we treat all entries in the TLE file as viable satellites, when in reality most are space junk.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing\n",
    "\n",
    "**Note:** we still need to _build_ these packages so this works. \n",
    "\n",
    "We recommend installing from conda, but any of these should work:\n",
    "\n",
    "| [Anaconda](https://www.anaconda.com/products/individual) | Pip | Git |\n",
    "| ---- | ---- | ---- |\n",
    "| `conda install -c <CONDA CHANNEL> jacobs-vault gh anaconda` | `pip install jacobs-vault` | `git clone git@github.com:cmorris-jacobs/jacobs-vault.git` |\n",
    "\n",
    "Alternatives:\n",
    "* [Miniconda](https://docs.conda.io/en/latest/miniconda.html): `conda install -c <CHANNEL> -c jacobs-vault` \n",
    "* Git https: `git clone https://github.com/cmorris-jacobs/jacobs-vault.git` \n",
    "\n",
    "## Using\n",
    "\n",
    "Change to the `jacobs-vault` folder and ensure that `data/` contains or points to the VAULT data. (SAY MORE!)  Then explore these options:\n",
    "\n",
    "### Demo\n",
    "```bash\n",
    "cd demo\n",
    ". run.sh\n",
    "```\n",
    "May require linking `demo/data` to the data folder, e.g. `ln -s ../data ./`. \n",
    "\n",
    "### Run the notebooks in nbs/\n",
    "Activate the `vault` Python virtual environment and start a new jupyter kernel.\n",
    "```bash\n",
    "conda env -f environment.yml\n",
    "conda activate vault\n",
    "jupyter notebook\n",
    "```\n",
    "You can now explore and run the notebooks in the `nbs/` folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About jacobs-vault"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jacobs-VAULT is the result of a hackathon challenge, so in addition to a working demo and analysis notebooks, it still has exploratory paths and alternate approaches. Folders are in three rough groups:\n",
    "\n",
    "### ETL Folders\n",
    "* `etl` - Original ETL scripts, mostly Spark SQL and Hive.\n",
    "* `ais-analytics` - Subproject Spark to analyze AIS data. Alternate ETL.\n",
    "* `geotransformer` - Subproject using Spark to analyze TLE data. Alternate ETL. Directly calls `sgp4` and the `astropy` package, instead of `skyfield`.\n",
    "\n",
    "### nbdev Folders\n",
    "A mix of exploratory notebooks and literate programming notebooks that generate Python modules and documentation (including this README) via the `nbdev` package. Controlled by the toplevel `Makefile`, using the `vault` virtual environment captured in `environment.yml`.  \n",
    "* `nbs` - Toplevel notebooks, generate docs, modules, and README.\n",
    "* `jacobs_vault` - Python modules generated from `nbs/` by `nbdev` package\n",
    "* `docs` - Documentation generated from `nbs/` by `nbdev` package\n",
    "* `data` - (See \"Demo Folders\".)\n",
    "\n",
    "### Demo Folders\n",
    "The demo supports a notebook with an interactive map-based walktrhough of getting AIS tracks, and querying a track for satellite coverage, using the `Skyfield` package for ephemeris calculations.  \n",
    "* `demo` - As much of the demo as possible lives under here, for completeness.\n",
    "* `data` - Daily satellite files stored (or linked) as`data/VAULT_Data/TLE_daily/`_year_`/`_MM_`/`_nn_`.tab.gz`. Used by the demo and other notebooks & scripts.  \n",
    "\n",
    "### Other folders\n",
    "* `autoencoder` - Exploratory work using a PyTorch deep network to discover high-level features and pattersn in the AIS data.\n",
    "* `ais-kml` - Concurrent visualization attempt using OpenSphere.\n",
    "* `hitttestservice` - First attempt to wrap HitTest code into a web service.\n",
    "* `scripts` - A collection of scripts, esp. SQL queries.\n",
    "\n",
    "\n",
    "### A note on Spark\n",
    "Some code expects an Apache Spark setup with Hive and Hadoop available. The `ais-analytics` and `geotransformer` folders contain `cookie-cutter` setups with scripts that \n",
    "will start Spark-enabled jupyter notebooks, or launch a spark job with the required virtual environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Required Packages\n",
    "\n",
    "After cloning the repository, use the `conda` package manager to install the main dependencies. (We provide files for `pip`, but we recommend conda.)\n",
    "```bash\n",
    "conda env create -f environment.yml\n",
    "```\n",
    "Key top-level packages fall in three broad categories:\n",
    "\n",
    "### Scientific Python Ecosystem:\n",
    "* Core: [numpy](https://numpy.org), [pandas](https://pandas.pydata.org)\n",
    "* Astronomy: [Skyfield](https://rhodesmill.org/skyfield/), [astropy](https://www.astropy.org), [GDAL](https://gdal.org), (pyorbital??)\n",
    "* Clustering: [HDBSCAN](https://hdbscan.readthedocs.io/en/latest/index.html)\n",
    "* Notebooks:  [ipython](https://ipython.org), [jupyter](https://jupyter.org) notebooks.\n",
    "\n",
    "### Cloud Computing\n",
    "* [Spark](https://spark.apache.org) including PySpark, [Hive](https://hive.apache.org), [Hadoop](https://hadoop.apache.org)\n",
    "* (Other database as req'd)\n",
    "* Map support: geopandas, ...\n",
    "* Visualization: plotly, (matplotlib?), (leaflet?), (opensphere?)\n",
    "\n",
    "### Literate Programming: \n",
    "* [nbdev](https://nbdev.fast.ai), [cookie-cutter](https://cookiecutter.readthedocs.io/en/latest/README.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests are automatically extracted from notebooks in `nbs/`. To run the tests in parallel, launch:\n",
    "\n",
    "`nbdev_test_nbs` or `make test`\n",
    "\n",
    "For all the tests to pass, you'll need to install the following optional dependencies:\n",
    "\n",
    "```\n",
    "pip install ...\n",
    "```\n",
    "\n",
    "Tests are written using <code>nbdev</code>, for example see the documentation for `hit_quality` or `viz`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can clone the repository and install dependencies with ...\n",
    "\n",
    "``` \n",
    "git clone https://github.com/cmorris-jacobs/jacobs-vault\n",
    "pip install -e \"jacobs-vault[dev]\"\n",
    "``` \n",
    "\n",
    "After you clone this repository, please run `nbdev_install_git_hooks` in your terminal. This sets up git hooks, which clean up the notebooks to remove the extraneous stuff stored in the notebooks (e.g. which cells you ran) which causes unnecessary merge conflicts.\n",
    "\n",
    "Before submitting a PR, check that the local library and notebooks match. The script `nbdev_diff_nbs` can let you know if there is a difference between the local library and the notebooks.\n",
    "\n",
    "- If you made a change to the *notebooks* in one of the exported cells, you can export it to the library with `nbdev_build_lib` or `make jacobs-vault`.\n",
    "- If you made a (small) change to the *library*, you can export it back to the notebooks with `nbdev_update_lib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not yet have official docker containers, but when done they should be available from [the github site](https://github.com/cmorris-jacobs/docker-containers#jacobs-vault)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jekyll": {
   "keywords": "fastai"
  },
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
