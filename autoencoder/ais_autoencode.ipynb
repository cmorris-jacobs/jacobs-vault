{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoding AIS data\n",
    "### This notebook creates an autoencoding model: a neural network whose accuracy is measured by how well it recreates compressed data. It is the beginning of research into applying this unsupervised machine learning method to this data set.\n",
    "\n",
    "The model's trained state is saved in `autoencoder_state.txt` so it can be used to test its accuracy and evaluate other data sets. Changing values of constants (learning rate, number of epochs, batch size) will change the model. For future implementation, the saved state should have a timestamped name -- the better to evaluate multiple models.\n",
    "\n",
    "Also created: a file with aggregated data and all of the calculated losses, `ais_autoencode_all_losses.csv`, and another with the \"largest\" losses (determined in this exploratory case by visual inspection of the loss histogram), `ais_autoencode_large_losses.csv`.\n",
    "\n",
    "Finally: TSNE is a clustering algorithm that projects multidimensional features to a more human-comprehensible 2D or 3D space. In this case, TSNE was applied to the aggregated data to create two more features, `x` and `y` for graphing. This file is `aggs_tsne.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps to create the autoencoding model for AIS data...\n",
    "1. read in the data\n",
    "2. rename columns as necessary\n",
    "3. preprocess data\n",
    "4. create TabularDataset from normed data (identify categorical data to be converted to numerical)\n",
    "5. choose constants (epochs, learning rate, batch size)\n",
    "6. load data with DataLoader: include dataset, batch size, etc.\n",
    "7. instantiate Autoencoder\n",
    "8. define distance metric\n",
    "9. define optimizer\n",
    "10. convert data to floats\n",
    "11. Autoencoder.train()\n",
    "12. Train over the number of epochs, see how data separates itself out. See Autoencoder.eval()\n",
    "13. Identify elements in batches in each clump.\n",
    "14. What features stand out in those batches?\n",
    "15. Visualize with TSNE: Add x, y values to data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from autoencoder import TabularDataset, Autoencoder\n",
    "\n",
    "from fastai.tabular.all import *\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from typing import List\n",
    "import glob\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('ais.tsv', sep='\\t')\n",
    "data['dt'] = pd.to_datetime(data['dt'], format='%Y-%m-%dT%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_dictionary = {\n",
    "\t'sog': ['mean', 'min', 'max', 'std'],\n",
    "\t'dt': 'count', \n",
    "\t'length': 'mean',\n",
    "\t'width': 'mean', \n",
    "\t'draft': 'mean'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mmsi</th>\n",
       "      <th>dt</th>\n",
       "      <th>status</th>\n",
       "      <th>vesseltype</th>\n",
       "      <th colspan=\"4\" halign=\"left\">sog</th>\n",
       "      <th>dt</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>draft</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 16:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.82593</td>\n",
       "      <td>8.60000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>0.11633</td>\n",
       "      <td>27</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 17:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.51915</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.70000</td>\n",
       "      <td>3.40042</td>\n",
       "      <td>47</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 18:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.28936</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.80000</td>\n",
       "      <td>4.20922</td>\n",
       "      <td>47</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 19:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.43636</td>\n",
       "      <td>8.10000</td>\n",
       "      <td>8.60000</td>\n",
       "      <td>0.16857</td>\n",
       "      <td>44</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 20:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.36316</td>\n",
       "      <td>8.10000</td>\n",
       "      <td>8.50000</td>\n",
       "      <td>0.07136</td>\n",
       "      <td>38</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mmsi                  dt                  status vesseltype     sog  \\\n",
       "                                                                      mean   \n",
       "0  43676060 2015-01-09 16:00:00  under way using engine    0.00000 8.82593   \n",
       "1  43676060 2015-01-09 17:00:00  under way using engine    0.00000 6.51915   \n",
       "2  43676060 2015-01-09 18:00:00  under way using engine    0.00000 4.28936   \n",
       "3  43676060 2015-01-09 19:00:00  under way using engine    0.00000 8.43636   \n",
       "4  43676060 2015-01-09 20:00:00  under way using engine    0.00000 8.36316   \n",
       "\n",
       "                             dt   length   width   draft  \n",
       "      min     max     std count     mean    mean    mean  \n",
       "0 8.60000 9.00000 0.11633    27 32.00000 9.00000 4.00000  \n",
       "1 0.00000 8.70000 3.40042    47 32.00000 9.00000 4.00000  \n",
       "2 0.00000 8.80000 4.20922    47 32.00000 9.00000 4.00000  \n",
       "3 8.10000 8.60000 0.16857    44 32.00000 9.00000 4.00000  \n",
       "4 8.10000 8.50000 0.07136    38 32.00000 9.00000 4.00000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs = data.groupby(['mmsi', pd.Grouper(key='dt', freq='H'), 'status', 'vesseltype']).agg(agg_dictionary)\n",
    "aggs.reset_index(inplace=True)\n",
    "aggs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs.columns = ['_'.join(col).strip() for col in aggs.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs.rename(columns={'mmsi_':'mmsi', 'dt_':'dt', 'status_': 'status', 'vesseltype_':'vesseltype', \n",
    "                     'dt_count':'count', 'length_mean':'length', 'width_mean':'width', 'draft_mean':'draft'}, \n",
    "            inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs['vesseltype'] = aggs['vesseltype'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmsi</th>\n",
       "      <th>dt</th>\n",
       "      <th>status</th>\n",
       "      <th>vesseltype</th>\n",
       "      <th>sog_mean</th>\n",
       "      <th>sog_min</th>\n",
       "      <th>sog_max</th>\n",
       "      <th>sog_std</th>\n",
       "      <th>count</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>draft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 16:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>0</td>\n",
       "      <td>8.82593</td>\n",
       "      <td>8.60000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>0.11633</td>\n",
       "      <td>27</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 17:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>0</td>\n",
       "      <td>6.51915</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.70000</td>\n",
       "      <td>3.40042</td>\n",
       "      <td>47</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 18:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>0</td>\n",
       "      <td>4.28936</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.80000</td>\n",
       "      <td>4.20922</td>\n",
       "      <td>47</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 19:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>0</td>\n",
       "      <td>8.43636</td>\n",
       "      <td>8.10000</td>\n",
       "      <td>8.60000</td>\n",
       "      <td>0.16857</td>\n",
       "      <td>44</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 20:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>0</td>\n",
       "      <td>8.36316</td>\n",
       "      <td>8.10000</td>\n",
       "      <td>8.50000</td>\n",
       "      <td>0.07136</td>\n",
       "      <td>38</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mmsi                  dt                  status  vesseltype  sog_mean  \\\n",
       "0  43676060 2015-01-09 16:00:00  under way using engine           0   8.82593   \n",
       "1  43676060 2015-01-09 17:00:00  under way using engine           0   6.51915   \n",
       "2  43676060 2015-01-09 18:00:00  under way using engine           0   4.28936   \n",
       "3  43676060 2015-01-09 19:00:00  under way using engine           0   8.43636   \n",
       "4  43676060 2015-01-09 20:00:00  under way using engine           0   8.36316   \n",
       "\n",
       "   sog_min  sog_max  sog_std  count   length   width   draft  \n",
       "0  8.60000  9.00000  0.11633     27 32.00000 9.00000 4.00000  \n",
       "1  0.00000  8.70000  3.40042     47 32.00000 9.00000 4.00000  \n",
       "2  0.00000  8.80000  4.20922     47 32.00000 9.00000 4.00000  \n",
       "3  8.10000  8.60000  0.16857     44 32.00000 9.00000 4.00000  \n",
       "4  8.10000  8.50000  0.07136     38 32.00000 9.00000 4.00000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207257, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,   30,   72, 1004,   70,   79,   71, 1024, 1003, 1020, 1001,\n",
       "       1025, 1002, 1012, 1018,   74,   47,    4, 1005,   33, 1010, 1013,\n",
       "        110,   80,   84, 1022,    7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs['vesseltype'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sparse matrix for the vessel types: fishing, argo, tanker, tugtow, na, no idea..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_dictionary = {\n",
    "    0:'na',\n",
    "    4:'other', 7:'other', 33:'other', 47:'other', 110:'other', \n",
    "    1005:'other', 1010:'other', 1018:'other', 1020:'other', 1022:'other', \n",
    "    30:'fishing', 1001:'fishing', 1002:'fishing', \n",
    "    70:'cargo', 71:'cargo', 72:'cargo', 74:'cargo', 79:'cargo', 1003:'cargo', 1004:'cargo',\n",
    "    80:'tanker', 84:'tanker', 1024:'tanker',\n",
    "    1012:'passenger', 1013:'passenger',\n",
    "    1025:'tugtow'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs['vessel'] = aggs['vesseltype'].map(vessel_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmsi</th>\n",
       "      <th>dt</th>\n",
       "      <th>status</th>\n",
       "      <th>vesseltype</th>\n",
       "      <th>sog_mean</th>\n",
       "      <th>sog_min</th>\n",
       "      <th>sog_max</th>\n",
       "      <th>sog_std</th>\n",
       "      <th>count</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>draft</th>\n",
       "      <th>vessel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>228348900</td>\n",
       "      <td>2015-01-28 12:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1004</td>\n",
       "      <td>20.06250</td>\n",
       "      <td>19.60000</td>\n",
       "      <td>20.50000</td>\n",
       "      <td>0.24977</td>\n",
       "      <td>56</td>\n",
       "      <td>349.06000</td>\n",
       "      <td>42.80000</td>\n",
       "      <td>15.02000</td>\n",
       "      <td>cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>228348900</td>\n",
       "      <td>2015-01-28 13:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1004</td>\n",
       "      <td>19.87679</td>\n",
       "      <td>19.50000</td>\n",
       "      <td>20.20000</td>\n",
       "      <td>0.20449</td>\n",
       "      <td>56</td>\n",
       "      <td>349.06000</td>\n",
       "      <td>42.80000</td>\n",
       "      <td>15.02000</td>\n",
       "      <td>cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>228348900</td>\n",
       "      <td>2015-01-28 14:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1004</td>\n",
       "      <td>20.02609</td>\n",
       "      <td>19.70000</td>\n",
       "      <td>20.30000</td>\n",
       "      <td>0.13888</td>\n",
       "      <td>23</td>\n",
       "      <td>349.06000</td>\n",
       "      <td>42.80000</td>\n",
       "      <td>15.02000</td>\n",
       "      <td>cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>228353600</td>\n",
       "      <td>2015-01-29 22:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1004</td>\n",
       "      <td>17.22000</td>\n",
       "      <td>16.90000</td>\n",
       "      <td>17.50000</td>\n",
       "      <td>0.22804</td>\n",
       "      <td>5</td>\n",
       "      <td>334.00000</td>\n",
       "      <td>42.80000</td>\n",
       "      <td>14.50000</td>\n",
       "      <td>cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>228353600</td>\n",
       "      <td>2015-01-29 23:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1004</td>\n",
       "      <td>17.08667</td>\n",
       "      <td>16.50000</td>\n",
       "      <td>17.50000</td>\n",
       "      <td>0.21996</td>\n",
       "      <td>15</td>\n",
       "      <td>334.00000</td>\n",
       "      <td>42.80000</td>\n",
       "      <td>14.50000</td>\n",
       "      <td>cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>228353600</td>\n",
       "      <td>2015-01-30 00:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1004</td>\n",
       "      <td>16.37143</td>\n",
       "      <td>16.10000</td>\n",
       "      <td>16.90000</td>\n",
       "      <td>0.28702</td>\n",
       "      <td>7</td>\n",
       "      <td>334.00000</td>\n",
       "      <td>42.80000</td>\n",
       "      <td>14.50000</td>\n",
       "      <td>cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>228353600</td>\n",
       "      <td>2015-01-30 01:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1004</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>15.70000</td>\n",
       "      <td>16.30000</td>\n",
       "      <td>0.28284</td>\n",
       "      <td>5</td>\n",
       "      <td>334.00000</td>\n",
       "      <td>42.80000</td>\n",
       "      <td>14.50000</td>\n",
       "      <td>cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>228353600</td>\n",
       "      <td>2015-01-30 05:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1004</td>\n",
       "      <td>16.17500</td>\n",
       "      <td>15.80000</td>\n",
       "      <td>16.70000</td>\n",
       "      <td>0.45000</td>\n",
       "      <td>4</td>\n",
       "      <td>334.00000</td>\n",
       "      <td>42.80000</td>\n",
       "      <td>14.50000</td>\n",
       "      <td>cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>228353600</td>\n",
       "      <td>2015-01-30 06:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1004</td>\n",
       "      <td>16.79130</td>\n",
       "      <td>15.90000</td>\n",
       "      <td>17.80000</td>\n",
       "      <td>0.58188</td>\n",
       "      <td>46</td>\n",
       "      <td>334.00000</td>\n",
       "      <td>42.80000</td>\n",
       "      <td>14.50000</td>\n",
       "      <td>cargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>228353600</td>\n",
       "      <td>2015-01-30 07:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1004</td>\n",
       "      <td>16.01636</td>\n",
       "      <td>15.60000</td>\n",
       "      <td>16.40000</td>\n",
       "      <td>0.20884</td>\n",
       "      <td>55</td>\n",
       "      <td>334.00000</td>\n",
       "      <td>42.80000</td>\n",
       "      <td>14.50000</td>\n",
       "      <td>cargo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mmsi                  dt                  status  vesseltype  \\\n",
       "2000  228348900 2015-01-28 12:00:00  under way using engine        1004   \n",
       "2001  228348900 2015-01-28 13:00:00  under way using engine        1004   \n",
       "2002  228348900 2015-01-28 14:00:00  under way using engine        1004   \n",
       "2003  228353600 2015-01-29 22:00:00  under way using engine        1004   \n",
       "2004  228353600 2015-01-29 23:00:00  under way using engine        1004   \n",
       "2005  228353600 2015-01-30 00:00:00  under way using engine        1004   \n",
       "2006  228353600 2015-01-30 01:00:00  under way using engine        1004   \n",
       "2007  228353600 2015-01-30 05:00:00  under way using engine        1004   \n",
       "2008  228353600 2015-01-30 06:00:00  under way using engine        1004   \n",
       "2009  228353600 2015-01-30 07:00:00  under way using engine        1004   \n",
       "\n",
       "      sog_mean  sog_min  sog_max  sog_std  count    length    width    draft  \\\n",
       "2000  20.06250 19.60000 20.50000  0.24977     56 349.06000 42.80000 15.02000   \n",
       "2001  19.87679 19.50000 20.20000  0.20449     56 349.06000 42.80000 15.02000   \n",
       "2002  20.02609 19.70000 20.30000  0.13888     23 349.06000 42.80000 15.02000   \n",
       "2003  17.22000 16.90000 17.50000  0.22804      5 334.00000 42.80000 14.50000   \n",
       "2004  17.08667 16.50000 17.50000  0.21996     15 334.00000 42.80000 14.50000   \n",
       "2005  16.37143 16.10000 16.90000  0.28702      7 334.00000 42.80000 14.50000   \n",
       "2006  16.00000 15.70000 16.30000  0.28284      5 334.00000 42.80000 14.50000   \n",
       "2007  16.17500 15.80000 16.70000  0.45000      4 334.00000 42.80000 14.50000   \n",
       "2008  16.79130 15.90000 17.80000  0.58188     46 334.00000 42.80000 14.50000   \n",
       "2009  16.01636 15.60000 16.40000  0.20884     55 334.00000 42.80000 14.50000   \n",
       "\n",
       "     vessel  \n",
       "2000  cargo  \n",
       "2001  cargo  \n",
       "2002  cargo  \n",
       "2003  cargo  \n",
       "2004  cargo  \n",
       "2005  cargo  \n",
       "2006  cargo  \n",
       "2007  cargo  \n",
       "2008  cargo  \n",
       "2009  cargo  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs[2000:2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BYTES_TO_MB_DIV = 0.000001\n",
    "def print_memory_usage_of_data_frame(df):\n",
    "    mem = round(df.memory_usage().sum() * BYTES_TO_MB_DIV, 3) \n",
    "    print(\"Memory usage is \" + str(mem) + \" MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage is 21.555 MB\n"
     ]
    }
   ],
   "source": [
    "print_memory_usage_of_data_frame(aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmsi</th>\n",
       "      <th>dt</th>\n",
       "      <th>vesseltype</th>\n",
       "      <th>sog_mean</th>\n",
       "      <th>sog_min</th>\n",
       "      <th>sog_max</th>\n",
       "      <th>sog_std</th>\n",
       "      <th>count</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>draft</th>\n",
       "      <th>status_at anchor</th>\n",
       "      <th>status_engaged in fishing</th>\n",
       "      <th>status_moored</th>\n",
       "      <th>status_not under command</th>\n",
       "      <th>status_reserved for future use (10)</th>\n",
       "      <th>status_restricted maneuverability</th>\n",
       "      <th>status_undefined</th>\n",
       "      <th>status_under way sailing</th>\n",
       "      <th>status_under way using engine</th>\n",
       "      <th>vessel_cargo</th>\n",
       "      <th>vessel_fishing</th>\n",
       "      <th>vessel_na</th>\n",
       "      <th>vessel_other</th>\n",
       "      <th>vessel_passenger</th>\n",
       "      <th>vessel_tanker</th>\n",
       "      <th>vessel_tugtow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 16:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>8.82593</td>\n",
       "      <td>8.60000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>0.11633</td>\n",
       "      <td>27</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 17:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6.51915</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.70000</td>\n",
       "      <td>3.40042</td>\n",
       "      <td>47</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 18:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>4.28936</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.80000</td>\n",
       "      <td>4.20922</td>\n",
       "      <td>47</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 19:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>8.43636</td>\n",
       "      <td>8.10000</td>\n",
       "      <td>8.60000</td>\n",
       "      <td>0.16857</td>\n",
       "      <td>44</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43676060</td>\n",
       "      <td>2015-01-09 20:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>8.36316</td>\n",
       "      <td>8.10000</td>\n",
       "      <td>8.50000</td>\n",
       "      <td>0.07136</td>\n",
       "      <td>38</td>\n",
       "      <td>32.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       mmsi                  dt  vesseltype  sog_mean  sog_min  sog_max  \\\n",
       "0  43676060 2015-01-09 16:00:00           0   8.82593  8.60000  9.00000   \n",
       "1  43676060 2015-01-09 17:00:00           0   6.51915  0.00000  8.70000   \n",
       "2  43676060 2015-01-09 18:00:00           0   4.28936  0.00000  8.80000   \n",
       "3  43676060 2015-01-09 19:00:00           0   8.43636  8.10000  8.60000   \n",
       "4  43676060 2015-01-09 20:00:00           0   8.36316  8.10000  8.50000   \n",
       "\n",
       "   sog_std  count   length   width   draft  status_at anchor  \\\n",
       "0  0.11633     27 32.00000 9.00000 4.00000                 0   \n",
       "1  3.40042     47 32.00000 9.00000 4.00000                 0   \n",
       "2  4.20922     47 32.00000 9.00000 4.00000                 0   \n",
       "3  0.16857     44 32.00000 9.00000 4.00000                 0   \n",
       "4  0.07136     38 32.00000 9.00000 4.00000                 0   \n",
       "\n",
       "   status_engaged in fishing  status_moored  status_not under command  \\\n",
       "0                          0              0                         0   \n",
       "1                          0              0                         0   \n",
       "2                          0              0                         0   \n",
       "3                          0              0                         0   \n",
       "4                          0              0                         0   \n",
       "\n",
       "   status_reserved for future use (10)  status_restricted maneuverability  \\\n",
       "0                                    0                                  0   \n",
       "1                                    0                                  0   \n",
       "2                                    0                                  0   \n",
       "3                                    0                                  0   \n",
       "4                                    0                                  0   \n",
       "\n",
       "   status_undefined  status_under way sailing  status_under way using engine  \\\n",
       "0                 0                         0                              1   \n",
       "1                 0                         0                              1   \n",
       "2                 0                         0                              1   \n",
       "3                 0                         0                              1   \n",
       "4                 0                         0                              1   \n",
       "\n",
       "   vessel_cargo  vessel_fishing  vessel_na  vessel_other  vessel_passenger  \\\n",
       "0             0               0          1             0                 0   \n",
       "1             0               0          1             0                 0   \n",
       "2             0               0          1             0                 0   \n",
       "3             0               0          1             0                 0   \n",
       "4             0               0          1             0                 0   \n",
       "\n",
       "   vessel_tanker  vessel_tugtow  \n",
       "0              0              0  \n",
       "1              0              0  \n",
       "2              0              0  \n",
       "3              0              0  \n",
       "4              0              0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = pd.get_dummies(aggs, columns=['status', 'vessel'])\n",
    "one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage is 21.555 MB\n"
     ]
    }
   ],
   "source": [
    "print_memory_usage_of_data_frame(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just interesting to note that the one-hot encoding here did not save any space in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207257, 27)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['draft',\n",
       " 'sog_max',\n",
       " 'sog_mean',\n",
       " 'status_moored',\n",
       " 'status_at anchor',\n",
       " 'vessel_fishing',\n",
       " 'sog_std',\n",
       " 'length',\n",
       " 'status_engaged in fishing',\n",
       " 'sog_min',\n",
       " 'status_undefined',\n",
       " 'vessel_cargo',\n",
       " 'status_not under command',\n",
       " 'count',\n",
       " 'status_reserved for future use (10)',\n",
       " 'status_restricted maneuverability',\n",
       " 'status_under way using engine',\n",
       " 'vesseltype',\n",
       " 'status_under way sailing',\n",
       " 'vessel_passenger',\n",
       " 'vessel_tugtow',\n",
       " 'vessel_other',\n",
       " 'width',\n",
       " 'vessel_tanker',\n",
       " 'vessel_na']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = ['mmsi', 'dt']\n",
    "continuous = list(set(one_hot.columns)-set(categorical))\n",
    "continuous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not sure normalizing the one-hot encoded part of the data is useful.\n",
    "Also! Categorifying mmsi ... there should be a reverse-lookup dictionary to get it back later. Deal with this in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "to = TabularPandas(one_hot, procs=[Categorify, Normalize], cat_names=categorical, cont_names=continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fastai.tabular.core.TabularPandas"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmsi</th>\n",
       "      <th>dt</th>\n",
       "      <th>draft</th>\n",
       "      <th>sog_max</th>\n",
       "      <th>sog_mean</th>\n",
       "      <th>status_moored</th>\n",
       "      <th>status_at anchor</th>\n",
       "      <th>vessel_fishing</th>\n",
       "      <th>sog_std</th>\n",
       "      <th>length</th>\n",
       "      <th>status_engaged in fishing</th>\n",
       "      <th>sog_min</th>\n",
       "      <th>status_undefined</th>\n",
       "      <th>vessel_cargo</th>\n",
       "      <th>status_not under command</th>\n",
       "      <th>count</th>\n",
       "      <th>status_reserved for future use (10)</th>\n",
       "      <th>status_restricted maneuverability</th>\n",
       "      <th>status_under way using engine</th>\n",
       "      <th>vesseltype</th>\n",
       "      <th>status_under way sailing</th>\n",
       "      <th>vessel_passenger</th>\n",
       "      <th>vessel_tugtow</th>\n",
       "      <th>vessel_other</th>\n",
       "      <th>width</th>\n",
       "      <th>vessel_tanker</th>\n",
       "      <th>vessel_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>209</td>\n",
       "      <td>0.22725</td>\n",
       "      <td>1.04092</td>\n",
       "      <td>1.19560</td>\n",
       "      <td>-0.28562</td>\n",
       "      <td>-0.19603</td>\n",
       "      <td>-1.57311</td>\n",
       "      <td>-0.26734</td>\n",
       "      <td>-0.46603</td>\n",
       "      <td>-0.34151</td>\n",
       "      <td>1.30228</td>\n",
       "      <td>-0.41790</td>\n",
       "      <td>-0.40997</td>\n",
       "      <td>-0.04320</td>\n",
       "      <td>-0.85023</td>\n",
       "      <td>-0.03926</td>\n",
       "      <td>-0.03348</td>\n",
       "      <td>0.81377</td>\n",
       "      <td>-2.79489</td>\n",
       "      <td>-0.17070</td>\n",
       "      <td>-0.04873</td>\n",
       "      <td>-0.23939</td>\n",
       "      <td>-0.20350</td>\n",
       "      <td>-0.39686</td>\n",
       "      <td>-0.07177</td>\n",
       "      <td>4.75001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>210</td>\n",
       "      <td>0.22725</td>\n",
       "      <td>0.98316</td>\n",
       "      <td>0.71988</td>\n",
       "      <td>-0.28562</td>\n",
       "      <td>-0.19603</td>\n",
       "      <td>-1.57311</td>\n",
       "      <td>4.18455</td>\n",
       "      <td>-0.46603</td>\n",
       "      <td>-0.34151</td>\n",
       "      <td>-0.55239</td>\n",
       "      <td>-0.41790</td>\n",
       "      <td>-0.40997</td>\n",
       "      <td>-0.04320</td>\n",
       "      <td>0.31321</td>\n",
       "      <td>-0.03926</td>\n",
       "      <td>-0.03348</td>\n",
       "      <td>0.81377</td>\n",
       "      <td>-2.79489</td>\n",
       "      <td>-0.17070</td>\n",
       "      <td>-0.04873</td>\n",
       "      <td>-0.23939</td>\n",
       "      <td>-0.20350</td>\n",
       "      <td>-0.39686</td>\n",
       "      <td>-0.07177</td>\n",
       "      <td>4.75001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mmsi   dt   draft  sog_max  sog_mean  status_moored  status_at anchor  \\\n",
       "0     1  209 0.22725  1.04092   1.19560       -0.28562          -0.19603   \n",
       "1     1  210 0.22725  0.98316   0.71988       -0.28562          -0.19603   \n",
       "\n",
       "   vessel_fishing  sog_std   length  status_engaged in fishing  sog_min  \\\n",
       "0        -1.57311 -0.26734 -0.46603                   -0.34151  1.30228   \n",
       "1        -1.57311  4.18455 -0.46603                   -0.34151 -0.55239   \n",
       "\n",
       "   status_undefined  vessel_cargo  status_not under command    count  \\\n",
       "0          -0.41790      -0.40997                  -0.04320 -0.85023   \n",
       "1          -0.41790      -0.40997                  -0.04320  0.31321   \n",
       "\n",
       "   status_reserved for future use (10)  status_restricted maneuverability  \\\n",
       "0                             -0.03926                           -0.03348   \n",
       "1                             -0.03926                           -0.03348   \n",
       "\n",
       "   status_under way using engine  vesseltype  status_under way sailing  \\\n",
       "0                        0.81377    -2.79489                  -0.17070   \n",
       "1                        0.81377    -2.79489                  -0.17070   \n",
       "\n",
       "   vessel_passenger  vessel_tugtow  vessel_other    width  vessel_tanker  \\\n",
       "0          -0.04873       -0.23939      -0.20350 -0.39686       -0.07177   \n",
       "1          -0.04873       -0.23939      -0.20350 -0.39686       -0.07177   \n",
       "\n",
       "   vessel_na  \n",
       "0    4.75001  \n",
       "1    4.75001  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to.xs.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207257, 27)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to.xs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Must use a Dataset and not simply a dataframe for the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TabularDataset(to.xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "otto = Autoencoder(to.xs.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(otto.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the cell below was interrupted during its run after accidentally being restarted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(17.6778, grad_fn=<MseLossBackward>)\n",
      "loss tensor(32.1896, grad_fn=<MseLossBackward>)\n",
      "loss tensor(67.3849, grad_fn=<MseLossBackward>)\n",
      "loss tensor(88.3202, grad_fn=<MseLossBackward>)\n",
      "loss tensor(83.8947, grad_fn=<MseLossBackward>)\n",
      "loss tensor(54.3650, grad_fn=<MseLossBackward>)\n",
      "loss tensor(28.2253, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.7455, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3729, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.6338, grad_fn=<MseLossBackward>)\n",
      "loss tensor(16.0843, grad_fn=<MseLossBackward>)\n",
      "loss tensor(19.8149, grad_fn=<MseLossBackward>)\n",
      "loss tensor(23.2630, grad_fn=<MseLossBackward>)\n",
      "loss tensor(39.2549, grad_fn=<MseLossBackward>)\n",
      "loss tensor(62.7368, grad_fn=<MseLossBackward>)\n",
      "loss tensor(39.0340, grad_fn=<MseLossBackward>)\n",
      "loss tensor(39.4475, grad_fn=<MseLossBackward>)\n",
      "loss tensor(37.2279, grad_fn=<MseLossBackward>)\n",
      "loss tensor(62.9386, grad_fn=<MseLossBackward>)\n",
      "loss tensor(33.1338, grad_fn=<MseLossBackward>)\n",
      "loss tensor(96.0816, grad_fn=<MseLossBackward>)\n",
      "loss tensor(105.8892, grad_fn=<MseLossBackward>)\n",
      "loss tensor(47.6726, grad_fn=<MseLossBackward>)\n",
      "loss tensor(105.5277, grad_fn=<MseLossBackward>)\n",
      "loss tensor(107.0920, grad_fn=<MseLossBackward>)\n",
      "loss tensor(106.0259, grad_fn=<MseLossBackward>)\n",
      "loss tensor(51.7363, grad_fn=<MseLossBackward>)\n",
      "loss tensor(52.6440, grad_fn=<MseLossBackward>)\n",
      "loss tensor(41.5418, grad_fn=<MseLossBackward>)\n",
      "loss tensor(24.1721, grad_fn=<MseLossBackward>)\n",
      "loss tensor(17.9199, grad_fn=<MseLossBackward>)\n",
      "loss tensor(13.3911, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.4799, grad_fn=<MseLossBackward>)\n",
      "loss tensor(17.1110, grad_fn=<MseLossBackward>)\n",
      "loss tensor(37.3370, grad_fn=<MseLossBackward>)\n",
      "loss tensor(20.6094, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.2017, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.8962, grad_fn=<MseLossBackward>)\n",
      "loss tensor(17.9848, grad_fn=<MseLossBackward>)\n",
      "loss tensor(18.2650, grad_fn=<MseLossBackward>)\n",
      "loss tensor(15.8916, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.4534, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.5306, grad_fn=<MseLossBackward>)\n",
      "loss tensor(13.6161, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6892, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.6954, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.0234, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.2010, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.5344, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.8918, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.8869, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.3640, grad_fn=<MseLossBackward>)\n",
      "loss tensor(9.0323, grad_fn=<MseLossBackward>)\n",
      "loss tensor(9.0223, grad_fn=<MseLossBackward>)\n",
      "loss tensor(15.1347, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6215, grad_fn=<MseLossBackward>)\n",
      "loss tensor(9.5504, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1367, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.8713, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.8970, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.4374, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.6989, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.8283, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8252, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.5369, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.1141, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.9292, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.1062, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.5060, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.1129, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0556, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3462, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6436, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5115, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.9247, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.5393, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5311, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5484, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6362, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.1207, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2683, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9826, grad_fn=<MseLossBackward>)\n",
      "loss tensor(14.8137, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1019, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1378, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5665, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5331, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.2017, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.5631, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.0100, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6429, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2797, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4757, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4714, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4386, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6019, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8521, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1565, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.7714, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.3778, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.4044, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.1005, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0723, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4401, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.8593, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3386, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.1907, grad_fn=<MseLossBackward>)\n",
      "loss tensor(15.0316, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.8227, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.2726, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.5338, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0733, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9417, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2069, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.4846, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.7812, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.3481, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.6029, grad_fn=<MseLossBackward>)\n",
      "loss tensor(25.8713, grad_fn=<MseLossBackward>)\n",
      "loss tensor(15.0199, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2620, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8157, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7574, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4092, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.8200, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.8547, grad_fn=<MseLossBackward>)\n",
      "loss tensor(13.8311, grad_fn=<MseLossBackward>)\n",
      "loss tensor(22.5292, grad_fn=<MseLossBackward>)\n",
      "loss tensor(32.6577, grad_fn=<MseLossBackward>)\n",
      "loss tensor(49.3963, grad_fn=<MseLossBackward>)\n",
      "loss tensor(37.0899, grad_fn=<MseLossBackward>)\n",
      "loss tensor(18.0275, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.9007, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.7314, grad_fn=<MseLossBackward>)\n",
      "loss tensor(19.3150, grad_fn=<MseLossBackward>)\n",
      "loss tensor(31.9907, grad_fn=<MseLossBackward>)\n",
      "loss tensor(30.0711, grad_fn=<MseLossBackward>)\n",
      "loss tensor(15.0206, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4407, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.6767, grad_fn=<MseLossBackward>)\n",
      "loss tensor(19.2350, grad_fn=<MseLossBackward>)\n",
      "loss tensor(24.1708, grad_fn=<MseLossBackward>)\n",
      "loss tensor(13.4729, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2686, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.1031, grad_fn=<MseLossBackward>)\n",
      "loss tensor(16.1675, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.1447, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0944, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5873, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7782, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.5429, grad_fn=<MseLossBackward>)\n",
      "loss tensor(17.4121, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.5037, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2303, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6755, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0276, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9274, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3570, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4107, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8317, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0434, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2856, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7606, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4551, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6080, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2375, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8301, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7128, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2186, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6125, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2128, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1504, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8272, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2753, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5507, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5942, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4154, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5784, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2684, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0028, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9149, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6836, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9228, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2468, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2609, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0387, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8088, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7190, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7561, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0159, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8546, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9145, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5570, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1715, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2413, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.2101, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.0181, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4009, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7846, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2882, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5537, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6542, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6474, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7943, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0216, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4790, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1743, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7839, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3861, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5802, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6229, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3388, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6526, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6922, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0156, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8025, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5710, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2902, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7956, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7557, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8034, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1757, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6246, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8240, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2925, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9786, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2496, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0926, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7306, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2662, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8498, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7670, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6597, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3700, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3112, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3424, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7617, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7798, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4616, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9253, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1468, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7206, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1444, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5663, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5044, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8904, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4143, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2385, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5704, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5839, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3899, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4491, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2217, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7090, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0367, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3015, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4039, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9795, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8728, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.6949, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.9331, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.9009, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(1.4027, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2657, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5654, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5947, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4092, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6361, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.0324, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.7618, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8791, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8348, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0761, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7952, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7092, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1893, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3131, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8738, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9329, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2148, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8326, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1589, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4042, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9467, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8313, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5375, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2538, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3367, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3837, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4980, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6471, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8300, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0291, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2271, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3885, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4963, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5205, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4473, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3114, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1367, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9370, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7636, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6176, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4884, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3582, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2384, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1779, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2298, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6096, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4988, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3211, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3408, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3786, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5251, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8581, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9361, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0730, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3736, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3683, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0491, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0244, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7475, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4928, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.3295, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0505, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.7450, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1935, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.3810, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1448, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.6241, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3766, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.4429, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5491, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9536, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8487, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9177, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4064, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3735, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5062, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0064, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.0105, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8577, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5462, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3682, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1068, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8982, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5997, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5756, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4140, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4677, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8961, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6896, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6822, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7064, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3924, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0111, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9907, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.4315, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1995, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8887, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9214, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9397, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9672, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0746, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2208, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2566, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3575, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7149, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2146, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4407, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3497, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3916, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6741, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7332, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8660, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9651, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0186, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9801, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5304, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8720, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3219, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6781, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1625, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8405, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6953, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9238, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9765, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0664, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2025, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6788, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6137, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.2778, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8009, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1304, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7271, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3568, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9757, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6615, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3261, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3399, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9828, grad_fn=<MseLossBackward>)\n",
      "loss tensor(9.8515, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.5117, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8618, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0942, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4055, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6238, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7099, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0076, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5163, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1144, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6261, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4557, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.8530, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6297, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6275, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5564, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5425, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6614, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1973, grad_fn=<MseLossBackward>)\n",
      "loss tensor(13.3601, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.4931, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3770, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7825, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1722, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.8470, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.6105, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7624, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8117, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9771, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9968, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1283, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2729, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3931, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1717, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0691, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7831, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3468, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8582, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4386, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2043, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4347, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7171, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(2.0176, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7291, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3025, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4375, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0908, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8950, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2775, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0689, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6567, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2601, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6423, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9771, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1652, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5600, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3958, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2187, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3258, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0463, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7611, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2598, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7422, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2979, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1804, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3326, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5280, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2480, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8666, grad_fn=<MseLossBackward>)\n",
      "loss tensor(17.6924, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0122, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2190, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.4458, grad_fn=<MseLossBackward>)\n",
      "loss tensor(14.0398, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6975, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.8167, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1762, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5654, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9159, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4310, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3737, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1083, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4295, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.1301, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.7506, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6067, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.0350, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.9089, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.8141, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.3014, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.0703, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6147, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.5276, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3185, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.1669, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.7853, grad_fn=<MseLossBackward>)\n",
      "loss tensor(15.7113, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5114, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9060, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6897, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5089, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.8488, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.9902, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6103, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.0258, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.3212, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.4280, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7231, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5233, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.3938, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.8348, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.9480, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.9899, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3542, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2154, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0790, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9384, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.2271, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.9537, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.8637, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.4283, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9943, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4446, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1173, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5988, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9960, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6974, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.7092, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9539, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2964, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7246, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7292, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0720, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0150, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6915, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5664, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7163, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9143, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8998, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3186, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2084, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5958, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5887, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4665, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5745, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6090, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0808, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1680, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3226, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8271, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9086, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3122, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5621, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8307, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9048, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8721, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4058, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9185, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6772, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.2790, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3991, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4466, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4913, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4388, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3407, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2151, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1167, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.0893, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1214, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1801, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2026, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1851, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9021, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3629, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1205, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6476, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2651, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3871, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1300, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1122, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3723, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5198, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3097, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7791, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8173, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3987, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3977, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6328, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8689, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4437, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1166, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8318, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4056, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8919, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4153, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4088, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7812, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7173, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.8114, grad_fn=<MseLossBackward>)\n",
      "loss tensor(17.0285, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.9764, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.8762, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8131, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.3389, grad_fn=<MseLossBackward>)\n",
      "loss tensor(18.6686, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.8701, grad_fn=<MseLossBackward>)\n",
      "loss tensor(13.4677, grad_fn=<MseLossBackward>)\n",
      "loss tensor(23.1411, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.1617, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.0598, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1880, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1067, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0746, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8679, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6835, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5386, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9315, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9542, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6169, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6233, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.1015, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9877, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4594, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5174, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(1.9825, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0022, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9028, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3831, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1532, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2697, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6070, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5331, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.4245, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.4490, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.0612, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1828, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5227, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2672, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0807, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9239, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3147, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5339, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1424, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9472, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7161, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4950, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3698, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9634, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1362, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7762, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9810, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7822, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3763, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8682, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7064, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4375, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6313, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8678, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.9470, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.4744, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2118, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6310, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3192, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.5786, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.6068, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.4744, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0245, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6081, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1767, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.4793, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3344, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3067, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5987, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9345, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7920, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9040, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3354, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3623, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6905, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7088, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4607, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9657, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5727, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4946, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.0429, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.2087, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.4286, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0822, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2660, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1006, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.1408, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.4258, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9373, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1935, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9109, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.9467, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.8971, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0119, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2002, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.3185, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.0129, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.8666, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.7355, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1875, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9742, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2680, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.1080, grad_fn=<MseLossBackward>)\n",
      "loss tensor(27.9248, grad_fn=<MseLossBackward>)\n",
      "loss tensor(20.8694, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.8052, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3955, grad_fn=<MseLossBackward>)\n",
      "loss tensor(14.7319, grad_fn=<MseLossBackward>)\n",
      "loss tensor(27.2809, grad_fn=<MseLossBackward>)\n",
      "loss tensor(13.6020, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4552, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.9652, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0564, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9125, grad_fn=<MseLossBackward>)\n",
      "loss tensor(26.7435, grad_fn=<MseLossBackward>)\n",
      "loss tensor(50.5727, grad_fn=<MseLossBackward>)\n",
      "loss tensor(47.8276, grad_fn=<MseLossBackward>)\n",
      "loss tensor(14.8950, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7120, grad_fn=<MseLossBackward>)\n",
      "loss tensor(31.4507, grad_fn=<MseLossBackward>)\n",
      "loss tensor(47.6227, grad_fn=<MseLossBackward>)\n",
      "loss tensor(33.5319, grad_fn=<MseLossBackward>)\n",
      "loss tensor(26.9428, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.9081, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7644, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3738, grad_fn=<MseLossBackward>)\n",
      "loss tensor(29.0250, grad_fn=<MseLossBackward>)\n",
      "loss tensor(53.5960, grad_fn=<MseLossBackward>)\n",
      "loss tensor(52.0312, grad_fn=<MseLossBackward>)\n",
      "loss tensor(32.3267, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.5996, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1952, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.4003, grad_fn=<MseLossBackward>)\n",
      "loss tensor(28.9063, grad_fn=<MseLossBackward>)\n",
      "loss tensor(30.5953, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.1395, grad_fn=<MseLossBackward>)\n",
      "loss tensor(42.5230, grad_fn=<MseLossBackward>)\n",
      "loss tensor(17.9289, grad_fn=<MseLossBackward>)\n",
      "loss tensor(13.3511, grad_fn=<MseLossBackward>)\n",
      "loss tensor(72.4837, grad_fn=<MseLossBackward>)\n",
      "loss tensor(22.1180, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.3275, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.1537, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7168, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3623, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6449, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9614, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1657, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.7217, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3437, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7597, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0932, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5043, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2809, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2665, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4332, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8882, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4476, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0880, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6843, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1713, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1598, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8541, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6692, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.0911, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2298, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8059, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3635, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5010, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3866, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1307, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.0248, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1994, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8470, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.2889, grad_fn=<MseLossBackward>)\n",
      "loss tensor(17.4038, grad_fn=<MseLossBackward>)\n",
      "loss tensor(9.2115, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4726, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5147, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1068, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.0746, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5363, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9174, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3780, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2614, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7428, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0873, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3659, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4693, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1688, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6715, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1210, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.8484, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2609, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2877, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3775, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7882, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5667, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7184, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0533, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8278, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.7973, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(4.5237, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.4615, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7312, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.9254, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7572, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1158, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.5948, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5639, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6986, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5481, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8126, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8749, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9027, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.2880, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.2182, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0821, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8613, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9026, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7746, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5725, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3315, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7321, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.7523, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.9969, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.8151, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5640, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9950, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.7342, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9439, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2042, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8376, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1092, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.8485, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.4867, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4452, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4616, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.7200, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0271, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6581, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4732, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.6200, grad_fn=<MseLossBackward>)\n",
      "loss tensor(18.0458, grad_fn=<MseLossBackward>)\n",
      "loss tensor(14.4348, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.9174, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6144, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.9459, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.4627, grad_fn=<MseLossBackward>)\n",
      "loss tensor(14.3433, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.9069, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.7293, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.8313, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7070, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8176, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5446, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.6589, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.2204, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.7710, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9065, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7759, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8329, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.1592, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.7465, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0285, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5626, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9133, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.7848, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.3716, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.0383, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1445, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0103, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5783, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1902, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7538, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1668, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9801, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1224, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3120, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0512, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0244, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6046, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8182, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6105, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.5366, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.7353, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.4982, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5982, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9123, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2425, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7786, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9320, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7287, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5545, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6280, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4148, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.4302, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2623, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1444, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6815, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3510, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0471, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7141, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7054, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7096, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5988, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2962, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1400, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8481, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3481, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5375, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0272, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9665, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6240, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6614, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9670, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0195, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9157, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5294, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1207, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0003, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0352, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2292, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9752, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5586, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1092, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7525, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0240, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2386, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2112, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4955, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6605, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5634, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3015, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6086, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0422, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6805, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6636, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5322, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0862, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6777, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3043, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7979, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2209, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4808, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4255, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1322, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3918, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2804, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4182, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3805, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3105, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1888, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1410, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9100, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1196, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0843, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6648, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6245, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6038, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2624, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7729, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5253, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2305, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7926, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0588, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3649, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5597, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8078, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5594, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4510, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6538, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9618, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2416, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5241, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5566, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4795, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0824, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7086, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4842, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4016, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4080, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4505, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.4497, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3954, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4306, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4376, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5091, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0288, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6958, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2820, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.7487, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.4462, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.3246, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1756, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7986, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8751, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5158, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6104, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0434, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2436, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5968, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1986, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5053, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2060, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5220, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7987, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2204, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.8594, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.9452, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.4447, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8091, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4023, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5575, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4260, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9049, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5287, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6336, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0497, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8225, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3779, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6220, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1933, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6301, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3198, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5143, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3125, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6172, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3799, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8957, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0078, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1592, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7264, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2532, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1883, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8766, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0067, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9535, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4189, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4617, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1147, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4722, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5516, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0692, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5386, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2472, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6125, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6438, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2450, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6369, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8187, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3499, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3448, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3930, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3818, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4114, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5065, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5715, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5666, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0200, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8387, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2981, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2562, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2103, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3230, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7586, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5359, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3910, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8973, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9528, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8437, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5000, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.1723, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.0507, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5952, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1264, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8928, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2742, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2965, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5834, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8858, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2833, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2917, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5004, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7508, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1382, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6960, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4983, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6174, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9652, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1521, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9877, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8036, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6798, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6876, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8019, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0589, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1753, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4552, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3020, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7570, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3955, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7896, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4649, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9713, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.7019, grad_fn=<MseLossBackward>)\n",
      "loss tensor(17.1956, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.6139, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.5914, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.9775, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7857, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3149, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.0644, grad_fn=<MseLossBackward>)\n",
      "loss tensor(15.9585, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.7010, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.5965, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6121, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.7421, grad_fn=<MseLossBackward>)\n",
      "loss tensor(9.5622, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.2737, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3006, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1740, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0919, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7053, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3699, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5056, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.2907, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3545, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8035, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6872, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5563, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1299, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.2598, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9081, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7370, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.7476, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.2242, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6414, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8499, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0151, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5946, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.0717, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.0328, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.5612, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.8147, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9682, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1733, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0266, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5290, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.5466, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.3939, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.2107, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.2067, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9463, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9370, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7595, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.7767, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.7075, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.4185, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9016, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3148, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0877, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0607, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9703, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(2.8148, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7248, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5183, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1404, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9395, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3914, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5740, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5212, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6366, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6615, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2828, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5774, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7284, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3166, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3526, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.2973, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.6979, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.8777, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0998, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7426, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5280, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3906, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.0554, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.5848, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6199, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5900, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3045, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.4232, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.8204, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.7991, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.2207, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6001, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2091, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.7651, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.5365, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.2295, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2550, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4260, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9950, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0602, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3006, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4608, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4865, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5140, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7976, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4936, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0694, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1191, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6660, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7460, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1222, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5010, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6934, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4401, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8773, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5434, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5439, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6039, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.4657, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.5636, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.5356, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6123, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.1064, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2947, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3835, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4473, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0877, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8923, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8898, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0458, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2956, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5297, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6574, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7683, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7107, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9297, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1952, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6602, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0733, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5018, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2033, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2173, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4462, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7751, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9753, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0247, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8988, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5404, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2601, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1079, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1939, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3914, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5593, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5632, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4598, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2661, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1214, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6431, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.6149, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4584, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7209, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.6910, grad_fn=<MseLossBackward>)\n",
      "loss tensor(13.4076, grad_fn=<MseLossBackward>)\n",
      "loss tensor(33.9035, grad_fn=<MseLossBackward>)\n",
      "loss tensor(23.0757, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.4978, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3994, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9836, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.0832, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.6271, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.5528, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.9127, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.1714, grad_fn=<MseLossBackward>)\n",
      "loss tensor(16.6237, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.4215, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.9729, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.0812, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.5235, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.4799, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6103, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.0455, grad_fn=<MseLossBackward>)\n",
      "loss tensor(14.4202, grad_fn=<MseLossBackward>)\n",
      "loss tensor(28.1319, grad_fn=<MseLossBackward>)\n",
      "loss tensor(25.8346, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.5789, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3980, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2063, grad_fn=<MseLossBackward>)\n",
      "loss tensor(22.6576, grad_fn=<MseLossBackward>)\n",
      "loss tensor(19.3360, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.1111, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.5737, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.6088, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.8946, grad_fn=<MseLossBackward>)\n",
      "loss tensor(9.1465, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.6513, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.7546, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1243, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8695, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2902, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9830, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3796, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7024, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2335, grad_fn=<MseLossBackward>)\n",
      "loss tensor(35.4855, grad_fn=<MseLossBackward>)\n",
      "loss tensor(33.4302, grad_fn=<MseLossBackward>)\n",
      "loss tensor(13.6453, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1150, grad_fn=<MseLossBackward>)\n",
      "loss tensor(13.4356, grad_fn=<MseLossBackward>)\n",
      "loss tensor(22.3627, grad_fn=<MseLossBackward>)\n",
      "loss tensor(14.4435, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.8164, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.4104, grad_fn=<MseLossBackward>)\n",
      "loss tensor(23.5042, grad_fn=<MseLossBackward>)\n",
      "loss tensor(15.1856, grad_fn=<MseLossBackward>)\n",
      "loss tensor(13.0353, grad_fn=<MseLossBackward>)\n",
      "loss tensor(9.8019, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.9408, grad_fn=<MseLossBackward>)\n",
      "loss tensor(19.4808, grad_fn=<MseLossBackward>)\n",
      "loss tensor(14.0468, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9775, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.1938, grad_fn=<MseLossBackward>)\n",
      "loss tensor(15.4651, grad_fn=<MseLossBackward>)\n",
      "loss tensor(14.9900, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.3658, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.7278, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7830, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5754, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.1195, grad_fn=<MseLossBackward>)\n",
      "loss tensor(27.7063, grad_fn=<MseLossBackward>)\n",
      "loss tensor(16.6326, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2656, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.7528, grad_fn=<MseLossBackward>)\n",
      "loss tensor(15.6726, grad_fn=<MseLossBackward>)\n",
      "loss tensor(12.9185, grad_fn=<MseLossBackward>)\n",
      "loss tensor(36.7031, grad_fn=<MseLossBackward>)\n",
      "loss tensor(16.7303, grad_fn=<MseLossBackward>)\n",
      "loss tensor(9.3267, grad_fn=<MseLossBackward>)\n",
      "loss tensor(25.3184, grad_fn=<MseLossBackward>)\n",
      "loss tensor(36.7131, grad_fn=<MseLossBackward>)\n",
      "loss tensor(46.6520, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.1734, grad_fn=<MseLossBackward>)\n",
      "loss tensor(41.5115, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(65.4069, grad_fn=<MseLossBackward>)\n",
      "loss tensor(76.6028, grad_fn=<MseLossBackward>)\n",
      "loss tensor(37.2768, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.3153, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9573, grad_fn=<MseLossBackward>)\n",
      "loss tensor(21.2878, grad_fn=<MseLossBackward>)\n",
      "loss tensor(58.0826, grad_fn=<MseLossBackward>)\n",
      "loss tensor(106.3541, grad_fn=<MseLossBackward>)\n",
      "loss tensor(62.9685, grad_fn=<MseLossBackward>)\n",
      "loss tensor(10.0592, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.2541, grad_fn=<MseLossBackward>)\n",
      "loss tensor(58.7598, grad_fn=<MseLossBackward>)\n",
      "loss tensor(65.9676, grad_fn=<MseLossBackward>)\n",
      "loss tensor(29.5315, grad_fn=<MseLossBackward>)\n",
      "loss tensor(18.5661, grad_fn=<MseLossBackward>)\n",
      "loss tensor(23.8854, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9867, grad_fn=<MseLossBackward>)\n",
      "loss tensor(44.6353, grad_fn=<MseLossBackward>)\n",
      "loss tensor(91.5929, grad_fn=<MseLossBackward>)\n",
      "loss tensor(153.0824, grad_fn=<MseLossBackward>)\n",
      "loss tensor(13.9634, grad_fn=<MseLossBackward>)\n",
      "loss tensor(55.3873, grad_fn=<MseLossBackward>)\n",
      "loss tensor(115.5575, grad_fn=<MseLossBackward>)\n",
      "loss tensor(133.2974, grad_fn=<MseLossBackward>)\n",
      "loss tensor(92.1013, grad_fn=<MseLossBackward>)\n",
      "loss tensor(27.9335, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.2291, grad_fn=<MseLossBackward>)\n",
      "loss tensor(14.0355, grad_fn=<MseLossBackward>)\n",
      "loss tensor(26.4994, grad_fn=<MseLossBackward>)\n",
      "loss tensor(51.2265, grad_fn=<MseLossBackward>)\n",
      "loss tensor(95.2093, grad_fn=<MseLossBackward>)\n",
      "loss tensor(103.3235, grad_fn=<MseLossBackward>)\n",
      "loss tensor(9.0998, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5792, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.0858, grad_fn=<MseLossBackward>)\n",
      "loss tensor(18.8468, grad_fn=<MseLossBackward>)\n",
      "loss tensor(33.8342, grad_fn=<MseLossBackward>)\n",
      "loss tensor(35.6683, grad_fn=<MseLossBackward>)\n",
      "loss tensor(23.1179, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6969, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.4624, grad_fn=<MseLossBackward>)\n",
      "loss tensor(21.4240, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.8251, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3678, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5552, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3277, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0170, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4094, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6972, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6222, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3338, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1951, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6461, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.2069, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.5533, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5891, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2557, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7412, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7887, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.1362, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.4894, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0087, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3179, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.0473, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6684, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.8536, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.2272, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.2285, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8752, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2791, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1464, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8864, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9506, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8973, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1424, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0613, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8880, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8340, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1442, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5981, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6623, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4125, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3914, grad_fn=<MseLossBackward>)\n",
      "loss tensor(28.0776, grad_fn=<MseLossBackward>)\n",
      "loss tensor(35.0618, grad_fn=<MseLossBackward>)\n",
      "loss tensor(23.5497, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.3069, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9427, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4156, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3482, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.3308, grad_fn=<MseLossBackward>)\n",
      "loss tensor(9.2534, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.0910, grad_fn=<MseLossBackward>)\n",
      "loss tensor(9.5410, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.3531, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5388, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5780, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6822, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.8560, grad_fn=<MseLossBackward>)\n",
      "loss tensor(8.8487, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.0199, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0276, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4177, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.3714, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.7740, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7982, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3454, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9574, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4994, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8653, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4656, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6218, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6532, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5956, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4053, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8174, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2891, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5962, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8025, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6567, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5386, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9328, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2543, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6135, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2916, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7571, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4944, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7273, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8659, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7831, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9841, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2453, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0185, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5656, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5988, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6787, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0775, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7202, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1441, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1489, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8587, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6432, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7131, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9250, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1352, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0608, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7369, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3145, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2838, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4028, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0631, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2215, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7969, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5437, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7224, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7511, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3692, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1125, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1698, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3499, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4134, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5722, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6974, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8864, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1209, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1301, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7216, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4198, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2317, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6432, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1107, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6352, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5255, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1784, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9385, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5515, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9061, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5695, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4699, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1660, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1808, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3068, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.6968, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8547, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8121, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6087, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5421, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1887, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1707, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2685, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3965, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5706, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3675, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2621, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3151, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5341, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2067, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9721, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7214, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4038, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3780, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5393, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0034, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0598, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0116, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8810, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5880, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8114, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0378, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8469, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6502, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5354, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3186, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0372, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1737, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8403, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0182, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3984, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2403, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7825, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7260, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8637, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8944, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6247, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7511, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9350, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0983, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0980, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4517, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3871, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4163, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4258, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5121, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4383, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0522, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6918, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5012, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5904, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2872, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0092, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7184, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6956, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3945, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9925, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5168, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0747, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7045, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6264, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8349, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1351, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3078, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0749, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6631, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5903, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7865, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8484, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9356, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6609, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4371, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4047, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5201, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7030, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7290, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3731, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8514, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.9338, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.5972, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2936, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2050, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2967, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1300, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8460, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6214, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7939, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5769, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8666, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5766, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7605, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1486, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0846, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7167, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2785, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8129, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6302, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.2915, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1812, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6649, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7798, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7809, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.6343, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.0017, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.7065, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8735, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3642, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6841, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8184, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9015, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8117, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5888, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6852, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7187, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.3758, grad_fn=<MseLossBackward>)\n",
      "loss tensor(6.1069, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2106, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4487, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5692, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5882, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5313, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0028, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3743, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.9562, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.3124, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3328, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6181, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9649, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6740, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0726, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7444, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3910, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5044, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9652, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2250, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1231, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8488, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6051, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.3509, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.4506, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1885, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9740, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5395, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2966, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4757, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3861, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5125, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7007, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5252, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4968, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1188, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1544, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9805, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6738, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6414, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3897, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3675, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1749, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4307, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9969, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3344, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0307, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6197, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4845, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3952, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5645, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0464, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1556, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7099, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2088, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2305, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9796, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8070, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6016, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1383, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3406, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.8024, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6255, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6136, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2491, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2267, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9356, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5390, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3374, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3474, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4847, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.8035, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2648, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4495, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3849, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8406, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4671, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3513, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4398, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6269, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7959, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8757, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8762, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6815, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0155, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8102, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4554, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4798, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3793, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4590, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5104, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5082, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4907, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4727, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4341, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3509, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2344, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1480, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1500, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2308, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3088, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3036, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2497, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1860, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1121, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4114, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1956, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2923, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7208, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7331, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1025, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4802, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2740, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5584, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.6224, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.3510, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.8899, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.4348, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.3650, grad_fn=<MseLossBackward>)\n",
      "loss tensor(7.7987, grad_fn=<MseLossBackward>)\n",
      "loss tensor(11.5532, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.5474, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.4379, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.2349, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.2763, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7768, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7834, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1800, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.0550, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2647, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7073, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5759, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1674, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.2014, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8205, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1286, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8806, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4548, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0464, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.1212, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9366, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1401, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1405, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6641, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0375, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4710, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6985, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6672, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2929, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5864, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9892, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3545, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5417, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0591, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9389, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6291, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4708, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3618, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9199, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6026, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7567, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5659, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6013, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1301, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7228, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5414, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4061, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4223, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.2293, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1734, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1797, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9718, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0121, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1566, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3665, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9180, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5748, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4054, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6287, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7427, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1089, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5228, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4235, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8352, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6384, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4143, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8280, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8076, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8121, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8114, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9940, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4490, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6919, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3559, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5920, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6080, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8641, grad_fn=<MseLossBackward>)\n",
      "loss tensor(5.2020, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2497, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2125, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9161, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4626, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9008, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7104, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8505, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1980, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1344, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4795, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4330, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1581, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8239, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8586, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8799, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7997, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6277, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5106, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4278, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3598, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3014, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2411, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2326, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3172, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2540, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4150, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2675, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2885, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1014, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2115, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7683, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3178, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6759, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3037, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4585, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7741, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8643, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8244, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4939, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2377, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3576, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6182, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7238, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4012, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(0.2689, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4812, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6385, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5274, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3153, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9340, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8305, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0083, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1541, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9846, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5991, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3648, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8078, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8468, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1110, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2050, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5755, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6361, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7905, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3201, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8794, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9695, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0112, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3948, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7178, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6340, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4305, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2381, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7467, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8995, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1686, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8002, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0473, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4771, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9709, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3456, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0661, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6367, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3626, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2249, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3180, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2198, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2968, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5228, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8445, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8178, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8826, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8164, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5214, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3685, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2346, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2200, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3943, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6698, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5234, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5944, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4415, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2572, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8057, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2078, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5963, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9714, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7454, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7242, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.0614, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3438, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1028, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0056, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8775, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7604, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.6261, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0645, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4973, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8223, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.1117, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.8797, grad_fn=<MseLossBackward>)\n",
      "loss tensor(4.0421, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5226, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4715, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9006, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4096, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0598, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7175, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.0989, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5851, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6433, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0562, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8543, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4316, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8403, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9118, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7760, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4256, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0820, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3818, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3842, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7080, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1556, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2535, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9868, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.8345, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0584, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7754, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.5337, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0073, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7832, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5557, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5419, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6984, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2161, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0165, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8292, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3166, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9675, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5195, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6971, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5206, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1575, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2206, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7411, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5964, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9174, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.9338, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.2513, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2193, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1591, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4838, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4312, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9048, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0165, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9742, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9483, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8683, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9229, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8167, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9431, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8229, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6292, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3914, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2142, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.2502, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4931, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5513, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4308, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3709, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3202, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9226, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.2048, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.5770, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4567, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6072, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3813, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0295, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1670, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7282, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1622, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3988, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6575, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5840, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7910, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1386, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0611, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1559, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6646, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4739, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6475, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8058, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4095, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9975, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8783, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9385, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7065, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3270, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.7012, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1966, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3217, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6508, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3339, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4739, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8814, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2179, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(1.2161, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8675, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4106, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.1678, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2688, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9857, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6381, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1934, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0298, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6972, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8439, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5577, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8308, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8596, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5572, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9603, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7163, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1910, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6927, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5125, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3151, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.3081, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0661, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0057, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4610, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0329, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.4694, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0062, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7683, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5708, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4032, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1292, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4441, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3716, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3526, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8992, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2575, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3487, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4024, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8623, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4792, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4013, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4521, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7409, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8567, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1211, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7864, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4230, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9099, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5786, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5631, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8219, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8540, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8675, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.9686, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8922, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.6476, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.4087, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3632, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7020, grad_fn=<MseLossBackward>)\n",
      "loss tensor(3.6429, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.9485, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7837, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.0494, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3924, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.5560, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.7866, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.2372, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3165, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6764, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.1067, grad_fn=<MseLossBackward>)\n",
      "loss tensor(2.0234, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.7443, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.8291, grad_fn=<MseLossBackward>)\n",
      "loss tensor(0.3446, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8585, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.8682, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.9054, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.5504, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.6128, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.4839, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.3372, grad_fn=<MseLossBackward>)\n",
      "loss tensor(1.1231, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-6fc496736715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# backward --------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# keep a running total of loss for the batches in this epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "otto.float()\n",
    "otto.train()\n",
    "train_loss = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for batch in dls:     \n",
    "        # clear the optimizer of previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward ---------------------------------------------\n",
    "        output= otto(batch[1]) #batch is a list of three vectors: \n",
    "                # [y, cont_X, and cat_X]. We already converted categorical to continuous, so pass in batch[1]\n",
    "        loss = criterion(output, batch[1])\n",
    "        # backward --------------------------------------------\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # keep a running total of loss for the batches in this epoch\n",
    "        running_loss += loss.item()\n",
    "    # log\n",
    "    lossb = running_loss / len(dls)\n",
    "    train_loss.append(lossb)\n",
    "    print('epoch [{}/{}], loss:{:.4f}'.format(epoch + 1, NUM_EPOCHS, loss.data), lossb)\n",
    "    \n",
    "otto.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './autoencoder_state.txt'\n",
    "torch.save(otto.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=27, out_features=13, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=13, out_features=6, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=6, out_features=13, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=13, out_features=27, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "otto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f023a7dbac0>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(NUM_EPOCHS)], train_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use the trained model to find records with the greatest losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f021af9d100>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "item_losses = []\n",
    "for item in evaluate:\n",
    "        # clear the optimizer of previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward ---------------------------------------------\n",
    "        output= otto(batch[1]) #batch is a list of three vectors: \n",
    "                # [y, cont_X, and cat_X]. We already converted categorical to continuous, so pass in batch[1]\n",
    "        loss = criterion(output, batch[1])\n",
    "        # backward --------------------------------------------\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # append to the list of losses for each item\n",
    "        item_losses.append(loss.item())\n",
    "plt.plot([i for i in range(len(item_losses))], item_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now `item_losses` can be a column in the aggregated dataset \n",
    "so we can attach the loss to the mmsi and date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207257"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(item_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs['autoencode_loss'] = item_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mmsi', 'dt', 'status', 'vesseltype', 'sog_mean', 'sog_min', 'sog_max',\n",
       "       'sog_std', 'count', 'length', 'width', 'draft', 'vessel',\n",
       "       'autoencode_loss'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mmsi</th>\n",
       "      <th>dt</th>\n",
       "      <th>status</th>\n",
       "      <th>vesseltype</th>\n",
       "      <th>sog_mean</th>\n",
       "      <th>sog_min</th>\n",
       "      <th>sog_max</th>\n",
       "      <th>sog_std</th>\n",
       "      <th>count</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>draft</th>\n",
       "      <th>vessel</th>\n",
       "      <th>autoencode_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30582</th>\n",
       "      <td>338945000</td>\n",
       "      <td>2015-01-13 09:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1018</td>\n",
       "      <td>6.10784</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>1.72335</td>\n",
       "      <td>51</td>\n",
       "      <td>86.14000</td>\n",
       "      <td>15.24000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>other</td>\n",
       "      <td>0.60678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30581</th>\n",
       "      <td>338945000</td>\n",
       "      <td>2015-01-13 08:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1018</td>\n",
       "      <td>6.92703</td>\n",
       "      <td>1.80000</td>\n",
       "      <td>10.60000</td>\n",
       "      <td>2.27799</td>\n",
       "      <td>37</td>\n",
       "      <td>86.14000</td>\n",
       "      <td>15.24000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>other</td>\n",
       "      <td>0.57964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9543</th>\n",
       "      <td>303303000</td>\n",
       "      <td>2015-01-19 01:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.04909</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.90000</td>\n",
       "      <td>0.16429</td>\n",
       "      <td>55</td>\n",
       "      <td>36.28000</td>\n",
       "      <td>8.54000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>fishing</td>\n",
       "      <td>0.50519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9542</th>\n",
       "      <td>303303000</td>\n",
       "      <td>2015-01-19 00:00:00</td>\n",
       "      <td>under way using engine</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.01667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.10000</td>\n",
       "      <td>0.03762</td>\n",
       "      <td>54</td>\n",
       "      <td>36.28000</td>\n",
       "      <td>8.54000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>fishing</td>\n",
       "      <td>0.50237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6023</th>\n",
       "      <td>303159000</td>\n",
       "      <td>2015-01-07 23:00:00</td>\n",
       "      <td>engaged in fishing</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>53</td>\n",
       "      <td>39.93000</td>\n",
       "      <td>9.76000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>fishing</td>\n",
       "      <td>0.44794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mmsi                  dt                  status  vesseltype  \\\n",
       "30582  338945000 2015-01-13 09:00:00  under way using engine        1018   \n",
       "30581  338945000 2015-01-13 08:00:00  under way using engine        1018   \n",
       "9543   303303000 2015-01-19 01:00:00  under way using engine        1001   \n",
       "9542   303303000 2015-01-19 00:00:00  under way using engine        1001   \n",
       "6023   303159000 2015-01-07 23:00:00      engaged in fishing        1001   \n",
       "\n",
       "       sog_mean  sog_min  sog_max  sog_std  count   length    width   draft  \\\n",
       "30582   6.10784  4.00000  9.00000  1.72335     51 86.14000 15.24000 0.00000   \n",
       "30581   6.92703  1.80000 10.60000  2.27799     37 86.14000 15.24000 0.00000   \n",
       "9543    0.04909  0.00000  0.90000  0.16429     55 36.28000  8.54000 0.00000   \n",
       "9542    0.01667  0.00000  0.10000  0.03762     54 36.28000  8.54000 0.00000   \n",
       "6023    0.00000  0.00000  0.00000  0.00000     53 39.93000  9.76000 0.00000   \n",
       "\n",
       "        vessel  autoencode_loss  \n",
       "30582    other          0.60678  \n",
       "30581    other          0.57964  \n",
       "9543   fishing          0.50519  \n",
       "9542   fishing          0.50237  \n",
       "6023   fishing          0.44794  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs.sort_values('autoencode_loss', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   207257.00000\n",
       "mean         0.01271\n",
       "std          0.02935\n",
       "min          0.00011\n",
       "25%          0.00036\n",
       "50%          0.00130\n",
       "75%          0.00892\n",
       "max          0.60678\n",
       "Name: autoencode_loss, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggs['autoencode_loss'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "aggs['autoencode_loss'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = aggs['autoencode_loss'] > 0.15\n",
    "big_diffs = aggs[filt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1982, 14)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_diffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_diffs.to_csv('ais_autoencode_large_losses.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs.to_csv('ais_autoencode_all_losses.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restarted the kernel at some point and did not re-run the cells below because of time and already had the augmented tsne data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE().fit_transform(to.xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=tsne[:,0], y=tsne[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs['x'] = tsne[:,0]\n",
    "aggs['y'] = tsne[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs.to_csv('aggs_tsne.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
